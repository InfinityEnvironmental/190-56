---
title: "Import Coastal Water Quality Data"
author: "Francois van Schalkwyk"
date: "2025-03-19"
output: html_document
---

# Workspace Set-Up

Make sure that you are working in the outfalls project, found in the working directory.

## Set working directory for all code chunks to project root directory

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
```

## Load required packages

```{r message = FALSE}
library(tidyverse)
library(dbplyr)
library(DBI)
library(pdftools)
library(readxl)
library(tesseract)
```

## Database Connection

```{r db connection}
# Enter credentials when prompted
con <- dbConnect(RPostgres::Postgres(),
  host = "aws-0-eu-central-1.pooler.supabase.com",
  port = 5432,
  user = str_c(rstudioapi::askForPassword(prompt = "Username: "), "wnrvdvesovnkmqbhkhjz", sep = "."),
  password = rstudioapi::askForPassword(),
  dbname = "postgres"
)
```

```{r}
dbGetInfo(con)
```

# Data Import

## Weekly Samples

### Check which pdf files have not yet been imported

```{r not-yet-imported}
# List of files in folder
files_list <- list.files("../../Infinity/Coastal Water Quality - Documents/Shared Results/SSB CMB Monitoring/", pattern = "*.pdf")

extract_sample_date <- function(filename){
  sample_date <- pdf_text(paste("../../Infinity/Coastal Water Quality - Documents/Shared Results/SSB CMB Monitoring/", filename, sep = "")) |>
    str_split("\\n") |>
    unlist() |>
    keep(~str_detect(.x, "Sample taken")) |>
    str_extract("\\d{1,2}\\s[:alpha:]{3,12}\\s\\d{4}") |>
    pluck(1) |>
    dmy()
  
  tibble(filename = filename, sample_date = sample_date)
}

# Map the function across the list of files in the directory
files <- map_df(files_list, ~extract_sample_date(.x))

# Retrieve a list of sample dates from the results table in database
database <- tbl(con, I("coastal.results")) |>
  distinct(filename) |>
  collect() |>
  arrange(desc(filename))

# Check which files are not yet in database
files |>
  left_join(database, by = c("filename" = "filename"), keep = TRUE) |>
  filter(is.na(filename.y))
```

### Extract data from pdf

```{r extract-pdf}
# Select the pdf that you want to import
path <- "../../Infinity/Coastal Water Quality - Documents/Shared Results/SSB CMB Monitoring/CWQ_206(24.10.2025).pdf"

filename <- str_remove(path, "../../Infinity/Coastal Water Quality - Documents/Shared Results/SSB CMB Monitoring/")

# Extract the pdf data
pdf_data <- pdf_text(path) |>
  str_split("\n")

# Extract the sample date
sample_date <- pdf_data |>
  unlist() |> 
  keep(~str_detect(.x, "Sample taken")) |>
  str_extract("\\d{1,2}\\s[:alpha:]{3,12}\\s\\d{4}") |>
  pluck(1) |>
  dmy()

# Extract the analysis date
analysis_completed <- pdf_data |>
  unlist() |> 
  keep(~str_detect(.x, "Analysis completed")) |>
  str_extract("\\d{1,2}\\s[:alpha:]{3,12}\\s\\d{4}") |>
  pluck(1) |>
  dmy()

# Extract the sample temperature
sample_temp_c <- pdf_data |>
  unlist() |> 
  keep(~str_detect(.x, "Sample temperature:")) |>
  str_extract("(?<=(Sample temperature:\\s))\\d{1,2}\\.\\d") |>
  pluck(1) |>
  as.numeric()

# Extract tabular data
extract_table <- function(page){
  page |>
    unlist() |> 
    head_while(~!str_detect(.x, "colony forming units")) |>
    tail_while(~!str_detect(.x, "Sample number")) |>
    discard(~.x == "") |>
    unlist()
}

# Extract table from all pages of pdf
table <- map(pdf_data, ~extract_table(.x)) |>
  unlist()

# Extract sample number
sample_number <- table |>
  str_sub(5,15) |>
  str_trim()

# Extract sample text
sample_text <- table |>
  str_sub(15,95) |>
  str_trim()

# Extract result
sample_result <- table |>
  str_sub(100) |>
  str_trim()

# Make a table with the extracted data
tbl <- tibble(number = sample_number,
       text = sample_text,
       result = sample_result) |> 
  mutate(number = if_else(number == "", NA, number)) |>
  fill(number, .direction = "down") |> 
  group_by(number) |>
  summarise(text = str_c(text, collapse = ""), result = first(result)) |>
  select(text, result) |>
  mutate(
    site_id = str_extract(text, "[:upper:]{2,3}\\d{2}\\d?[AOIWETC]?") |> str_remove_all("\\s"),
    sample_time = str_extract(text, "\\d{1,2}h\\d{2}") |> str_replace("h", ":"),
    sample_date = sample_date,
    analysis_completed = analysis_completed,
    sample_temp_c = sample_temp_c,
    filename = filename
    ) |>
  select(-text) |>
  rename(enterococci_cfu_per_100ml = result) |>
  mutate(site_id = case_when(
    str_detect(site_id, "\\d{3}") & str_detect(site_id, "1$") ~ str_replace(site_id, "1$", "I"),
    str_detect(site_id, "\\d{3}") & str_detect(site_id, "0$") ~ str_replace(site_id, "0$", "O"),
    .default = site_id
  )) |>
  mutate(enterococci_cfu_per_100ml = str_replace(enterococci_cfu_per_100ml, "None found", "ND"))

# Check data
tbl

# Copy to database
tbl |>
  copy_to(dest = con, name = "coastal", overwrite = TRUE)
```

### Upload to database

```{sql, connection = con}
BEGIN;
```

```{sql, connection = con}
SELECT * FROM coastal;
```

```{sql, connection = con}
WITH cte AS 
(SELECT
  site_id,
  sample_date,
  sample_time::time,
  analysis_completed,
  sample_temp_c,
  enterococci_cfu_per_100ml,
  filename,
  'WLAB'::coastal.lab AS lab_code,
  'routine'::coastal.monitoring_group AS monitoring_group
FROM coastal)
INSERT INTO coastal.results (site_id, sample_date, sample_time, analysis_completed, sample_temp_c, enterococci_cfu_per_100ml, filename, lab_code, monitoring_group)
SELECT * FROM cte;
```

```{sql, connection = con}
SELECT
  site_id, sample_date, sample_time, enterococci_cfu_per_100ml, sample_temp_c, filename
FROM coastal.results
WHERE sample_date = '2025-10-24' AND monitoring_group = 'routine';
```

```{sql, connection = con}
ROLLBACK;
```

```{sql, connection = con}
COMMIT;
```

### Upload single sample values

```{sql connection = con}
BEGIN;
```

```{sql connection = con}
INSERT INTO coastal.results (site_id, sample_date, sample_time, analysis_completed, sample_temp_c, enterococci_cfu_per_100ml, filename, lab_code, monitoring_group)
SELECT
  'XCS28' AS site_id,
  '2025-10-22'::date AS sample_date,
  '11:17'::time AS sample_time,
  '2025-10-24'::date AS analysis_completed,
   3.1 AS sample_temp_c,
  '9' AS enterococci_cfu_per_100ml,
  'CWQ_203(22.10.2025).pdf' AS filename,
  'WLAB'::coastal.lab AS lab_code,
  'routine'::coastal.monitoring_group AS monitoring_group;
```

```{sql connection = con}
SELECT * FROM coastal.results WHERE sample_date = '2025-10-22' AND monitoring_group = 'routine';
```

```{sql connection = con}
ROLLBACK;
```

```{sql connection = con}
COMMIT;
```

## Daily Samples Strand

### Check which pdf files have not yet been imported

```{r not-yet-imported}
# List of files in folder
files_list <- list.files("../../Infinity/Coastal Water Quality - Documents/Shared Results/Strand Daily/", pattern = "*.pdf")

extract_sample_date <- function(filename){
  sample_date <- pdf_text(paste("../../Infinity/Coastal Water Quality - Documents/Shared Results/Strand Daily/", filename, sep = "")) |>
    str_split("\\n") |>
    unlist() |>
    keep(~str_detect(.x, "Sample taken")) |>
    str_extract("\\d{1,2}\\s[:alpha:]{3,12}\\s\\d{4}") |>
    pluck(1) |>
    dmy()
  
  tibble(filename = filename, sample_date = sample_date)
}

# Map the function across the list of files in the directory
files <- map_df(files_list, ~extract_sample_date(.x))

# Retrieve a list of sample dates from the results table in database
database <- tbl(con, I("coastal.results")) |>
  filter(monitoring_group == "daily") |>
  distinct(filename) |>
  collect() |>
  arrange(desc(filename))

# Check which files are not yet in database
files |>
  left_join(database, by = c("filename" = "filename"), keep = TRUE) |>
  filter(is.na(filename.y))
```

### Extract data from pdf

```{r extract-pdf}
# Select the pdf that you want to import
path <- "../../Infinity/Coastal Water Quality - Documents/Shared Results/Strand Daily/Oelofse G.191.pdf"

filename <- str_remove(path, "../../Infinity/Coastal Water Quality - Documents/Shared Results/Strand Daily/")

# Extract the pdf data
pdf_data <- pdf_text(path) |>
  str_split("\n")

# Extract the sample date
sample_date <- pdf_data |>
  unlist() |> 
  keep(~str_detect(.x, "Sample taken")) |>
  str_extract("\\d{1,2}\\s[:alpha:]{3,12}\\s\\d{4}") |>
  pluck(1) |>
  dmy()

# Extract the analysis date
analysis_completed <- pdf_data |>
  unlist() |> 
  keep(~str_detect(.x, "Analysis completed")) |>
  str_extract("\\d{1,2}\\s[:alpha:]{3,12}\\s\\d{4}") |>
  pluck(1) |>
  dmy()

# Extract the sample temperature
sample_temp_c <- pdf_data |>
  unlist() |> 
  keep(~str_detect(.x, "Sample temperature:")) |>
  str_extract("(?<=(Sample temperature:\\s))\\d{1,2}\\.\\d") |>
  pluck(1) |>
  as.numeric()

# Extract tabular data
extract_table <- function(page){
  page |>
    unlist() |> 
    head_while(~!str_detect(.x, "colony forming units")) |>
    tail_while(~!str_detect(.x, "Sample number")) |>
    discard(~.x == "") |>
    unlist()
}

# Extract table from all pages of pdf
table <- map(pdf_data, ~extract_table(.x)) |>
  unlist()

# Extract sample number
sample_number <- table |>
  str_sub(1,15) |>
  str_trim()

# Extract sample text
sample_text <- table |>
  str_sub(15,95) |>
  str_trim()

# Extract result
sample_result <- table |>
  str_sub(100) |>
  str_trim()

# Make a table with the extracted data
tbl <- tibble(number = sample_number,
       text = sample_text,
       result = sample_result) |> 
  mutate(number = if_else(number == "", NA, number)) |>
  fill(number, .direction = "down") |> 
  group_by(number) |>
  summarise(text = str_c(text, collapse = ""), result = first(result)) |>
  select(text, result) |>
  mutate(
      site_id = case_when(
        text |> str_to_lower() |> str_detect("cape|sands") ~ "XCS34",
        text |> str_to_lower() |> str_detect("blue|building") ~ "XCS26",
        .default = text
      ),
      sample_time = str_extract(text, "\\d{1,2}h\\d{2}") |> str_replace("h", ":"),
      sample_date = sample_date,
      analysis_completed = analysis_completed,
      sample_temp_c = sample_temp_c,
      filename = filename |> str_remove(path),
      monitoring_group = if_else(str_detect(text, "Backline"), "adhoc", "daily")
      ) |>
  select(-text) |>
  rename(enterococci_cfu_per_100ml = result) |>
  mutate(enterococci_cfu_per_100ml = str_replace(enterococci_cfu_per_100ml, "None found", "ND"))

# Check data
tbl

# Copy to database
copy_to(con, tbl, name = "coastal", overwrite = TRUE)
```

### Upload to database

```{sql, connection = con}
BEGIN;
```

```{sql, connection = con}
WITH cte AS 
(SELECT
  site_id,
  sample_date,
  sample_time::time,
  analysis_completed,
  sample_temp_c,
  enterococci_cfu_per_100ml,
  filename,
  'WLAB'::coastal.lab AS lab_code,
  monitoring_group::coastal.monitoring_group
FROM coastal)
INSERT INTO coastal.results (site_id, sample_date, sample_time, analysis_completed, sample_temp_c, enterococci_cfu_per_100ml, filename, lab_code, monitoring_group)
SELECT * FROM cte;
```

```{sql, connection = con}
SELECT
  site_id, sample_date, sample_time, enterococci_cfu_per_100ml, monitoring_group
FROM coastal.results
WHERE monitoring_group = 'daily' AND sample_date = '2025-10-15';
```

```{sql, connection = con}
ROLLBACK;
```

```{sql, connection = con}
COMMIT;
```

## Daily Samples Atlantic

### Check which pdf files have not yet been imported

```{r not-yet-imported}
# List of files in folder
files_list <- list.files("../../Infinity/Coastal Water Quality - Documents/Shared Results/Atlantic Daily/", pattern = "*.pdf")

extract_sample_date <- function(filename){
  sample_date <- pdf_text(paste("../../Infinity/Coastal Water Quality - Documents/Shared Results/Atlantic Daily/", filename, sep = "")) |>
    str_split("\\n") |>
    unlist() |>
    keep(~str_detect(.x, "Sample taken")) |>
    str_extract("\\d{1,2}\\s[:alpha:]{3,12}\\s\\d{4}") |>
    pluck(1) |>
    dmy()
  
  tibble(filename = filename, sample_date = sample_date)
}

# Map the function across the list of files in the directory
files <- map_df(files_list, ~extract_sample_date(.x))

# Retrieve a list of sample dates from the results table in database
database <- tbl(con, I("coastal.results")) |>
  filter(monitoring_group == "daily") |>
  distinct(filename) |>
  collect() |>
  arrange(desc(filename))

# Check which files are not yet in database
files |>
  left_join(database, by = c("filename" = "filename"), keep = TRUE) |>
  filter(is.na(filename.y))
```

### Extract data from pdf

```{r extract-pdf}
# Select the pdf that you want to import
path <- "../../Infinity/Coastal Water Quality - Documents/Shared Results/Atlantic Daily/Infinity Environmental AD.277.pdf"
filename <- str_remove(path, "../../Infinity/Coastal Water Quality - Documents/Shared Results/Atlantic Daily/")

# Extract the pdf data
pdf_data <- pdf_text(path) |>
  str_split("\n")

# Extract the sample date
sample_date <- pdf_data |>
  unlist() |> 
  keep(~str_detect(.x, "Sample taken")) |>
  str_extract("\\d{1,2}\\s[:alpha:]{3,12}\\s\\d{4}") |>
  pluck(1) |>
  dmy()

# Extract the analysis date
analysis_completed <- pdf_data |>
  unlist() |> 
  keep(~str_detect(.x, "Analysis completed")) |>
  str_extract("\\d{1,2}\\s[:alpha:]{3,12}\\s\\d{4}") |>
  pluck(1) |>
  dmy()

# Extract the sample temperature
sample_temp_c <- pdf_data |>
  unlist() |> 
  keep(~str_detect(.x, "Sample temperature:")) |>
  str_extract("(?<=(Sample temperature:\\s))\\d{1,2}\\.\\d") |>
  pluck(1) |>
  as.numeric()

# Extract tabular data
extract_table <- function(page){
  page |>
    unlist() |> 
    head_while(~!str_detect(.x, "colony forming units")) |>
    tail_while(~!str_detect(.x, "Sample number")) |>
    discard(~.x == "") |>
    unlist()
}

# Extract table from all pages of pdf
table <- map(pdf_data, ~extract_table(.x)) |>
  unlist()

# Extract sample number
sample_number <- table |>
  str_sub(1,15) |>
  str_trim()

# Extract sample text
sample_text <- table |>
  str_sub(15,95) |>
  str_trim()

# Extract result
sample_result <- table |>
  str_sub(100) |>
  str_trim()

# Make a table with the extracted data
tbl <- tibble(number = sample_number,
       text = sample_text,
       result = sample_result) |> 
  mutate(number = if_else(number == "", NA, number)) |>
  fill(number, .direction = "down") |> 
  group_by(number) |>
  summarise(text = str_c(text, collapse = ""), result = first(result)) |>
  select(text, result) |>
  mutate(
      site_id = str_extract(text, "[:upper:]{2,3}\\s?\\d{2}\\d?\\s?[AOIWETC]?") |> str_remove_all("\\s"),
      sample_time = str_extract(text, "\\d{1,2}h\\d{2}") |> str_replace("h", ":"),
      sample_date = sample_date,
      analysis_completed = analysis_completed,
      sample_temp_c = sample_temp_c,
      filename = filename |> str_remove(path)
      ) |>
  select(-text) |>
  rename(enterococci_cfu_per_100ml = result) |>
  mutate(enterococci_cfu_per_100ml = str_replace(enterococci_cfu_per_100ml, "None found", "ND"))

# Check data
tbl

# Copy to database
copy_to(con, tbl, name = "coastal", overwrite = TRUE)
```

### Upload to database

```{sql, connection = con}
BEGIN;
```

```{sql, connection = con}
WITH cte AS 
(SELECT
  site_id,
  sample_date,
  sample_time::time,
  analysis_completed,
  sample_temp_c,
  enterococci_cfu_per_100ml,
  filename,
  'WLAB'::coastal.lab AS lab_code,
  'daily'::coastal.monitoring_group
FROM coastal)
INSERT INTO coastal.results (site_id, sample_date, sample_time, analysis_completed, sample_temp_c, enterococci_cfu_per_100ml, filename, lab_code, monitoring_group)
SELECT * FROM cte;
```

```{sql, connection = con}
SELECT
  site_id, sample_date, sample_time, enterococci_cfu_per_100ml
FROM coastal.results
WHERE monitoring_group = 'daily' AND sample_date = '2025-10-24';
```

```{sql, connection = con}
ROLLBACK;
```

```{sql, connection = con}
COMMIT;
```

## Daily Samples Saunders Rocks

```{r check-files}
# Prepare the data for
upload <- tibble(
  filename_short = list.files("../../Infinity/Coastal Water Quality - Documents/Shared Results/Saunders Rocks/"),
  filename_long = list.files("../../Infinity/Coastal Water Quality - Documents/Shared Results/Saunders Rocks/", full.names = T)
) |>
  mutate(pdf_data = map(filename_long, ~ pdf_text(.x) |>
    str_split("\n") |>
    unlist())) |>
  mutate(sample_date = map(pdf_data, ~keep(.x, ~str_detect(.x, "Sample taken")) |> str_remove("\\*Sample taken:") |> str_trim() |> dmy())) |>
  mutate(analysis_completed = map(pdf_data, ~keep(.x, ~str_detect(.x, "Analysis completed")) |> str_remove("Analysis completed:") |> str_trim() |> dmy())) |>
  mutate(sample_temp_c = map(pdf_data, ~keep(.x, ~str_detect(.x, "Sample temperature")) |> str_remove("Sample temperature:") |> str_trim() |> str_remove("ºC") |> as.numeric())) |>
  mutate(data = map(pdf_data, ~{
    .x |> tail_while(~!str_detect(.x, "Sample number")) |> head_while(~!str_detect(.x, "colony forming")) |> keep(~str_length(.x) > 0)
  })) |>
  mutate(site_id = map(data, ~str_extract(.x, "CN16\\s[BIO]") |> str_replace("\\s", ""))) |>
  mutate(sample_time = map(data, ~str_extract(.x, "\\d{2}h\\d{2}") |> str_replace("h", ":"))) |>
  mutate(censored_value = map(data, ~str_sub(.x, 35) |> str_trim() |> str_split("\\s{5,}"))) |>
  unnest(sample_date, analysis_completed, sample_temp_c, site_id, sample_time, censored_value) |>
  mutate(censored_value = map(censored_value, ~.x[[1]])) |>
  unnest(censored_value) |>
  select(site_id, sample_date, sample_time, analysis_completed, sample_temp_c, censored_value, filename_short) |>
  rename(enterococci_cfu_per_100ml = censored_value) |>
  mutate(enterococci_cfu_per_100ml = str_replace(enterococci_cfu_per_100ml, "None found", "ND")) |>
  filter(site_id != "CN16B")

# Upload to temporary table in the database
copy_to(con, upload, name = "saunders", temporary = T, overwrite = T)
```

```{sql, connection = con}
BEGIN;
```

```{sql, connection = con}
SELECT * FROM saunders;
```

```{sql, connection = con}
SELECT * FROM coastal.results;
```

```{sql, connection = con}
WITH cte AS
(SELECT
  site_id, sample_date, sample_time::time, analysis_completed, sample_temp_c, enterococci_cfu_per_100ml, filename_short AS filename, 'WLAB'::coastal.lab AS lab_code, 'daily'::coastal.monitoring_group AS monitoring_group
FROM saunders)
INSERT INTO coastal.results (site_id, sample_date, sample_time, analysis_completed, sample_temp_c, enterococci_cfu_per_100ml, filename, lab_code, monitoring_group)
SELECT * FROM cte;
```

```{sql, connection = con}
SELECT * FROM coastal.results WHERE monitoring_group = 'daily' AND site_id IN ('CN16I', 'CN16O');
```

```{sql, connection = con}
ROLLBACK;
```

```{sql, connection = con}
COMMIT;
```

## High-frequency Camps Bay sampling to database

### Check which pdf files have not yet been imported

```{r not-yet-imported}
# List of files in folder
files_list <- list.files("../../Infinity/Coastal Water Quality - Documents/Shared Results/Camps Bay High-Frequency Sampling/02 Data/", pattern = "*.pdf")

extract_sample_date <- function(filename){
  sample_date <- pdf_text(paste("../../Infinity/Coastal Water Quality - Documents/Shared Results/Camps Bay High-Frequency Sampling/02 Data/", filename, sep = "")) |>
    str_split("\\n") |>
    unlist() |>
    keep(~str_detect(.x, "Sample taken")) |>
    str_extract("\\d{1,2}\\s[:alpha:]{3,12}\\s\\d{4}") |>
    pluck(1) |>
    dmy()
  
  tibble(filename = filename, sample_date = sample_date)
}

# Map the function across the list of files in the directory
files <- map_df(files_list, ~extract_sample_date(.x))

# Retrieve a list of sample dates from the results table in database
database <- tbl(con, I("coastal.high_frequency_samples")) |>
  distinct(filename) |>
  collect() |>
  arrange(desc(filename))

# Check which files are not yet in database
files |>
  left_join(database, by = c("filename" = "filename"), keep = TRUE) |>
  filter(is.na(filename.y))
```

### Extract data from pdf

```{r extract-pdf}
# Select the pdf that you want to import
path <- "../../Infinity/Coastal Water Quality - Documents/Shared Results/Camps Bay High-Frequency Sampling/02 Data/Infinity Environmental AD.151(CN).pdf"
filename <- str_remove(path, "../../Infinity/Coastal Water Quality - Documents/Shared Results/Camps Bay High-Frequency Sampling/02 Data/")

# Extract the pdf data
pdf_data <- pdf_text(path) |>
  str_split("\n")

# Extract the sample date
sample_date <- pdf_data |>
  unlist() |> 
  keep(~str_detect(.x, "Sample taken")) |>
  str_extract("\\d{1,2}\\s[:alpha:]{3,12}\\s\\d{4}") |>
  pluck(1) |>
  dmy()

# Extract the analysis date
analysis_completed <- pdf_data |>
  unlist() |> 
  keep(~str_detect(.x, "Analysis completed")) |>
  str_extract("\\d{1,2}\\s[:alpha:]{3,12}\\s\\d{4}") |>
  pluck(1) |>
  dmy()

# Extract the sample temperature
sample_temp_c <- pdf_data |>
  unlist() |> 
  keep(~str_detect(.x, "Sample temperature:")) |>
  str_extract("(?<=(Sample temperature:\\s))\\d{1,2}\\.\\d") |>
  pluck(1) |>
  as.numeric()

# Extract tabular data
extract_table <- function(page){
  page |>
    unlist() |> 
    head_while(~!str_detect(.x, "colony forming units")) |>
    tail_while(~!str_detect(.x, "Sample Description")) |>
    discard(~.x == "") |>
    unlist()
}

# Extract table from all pages of pdf
table <- map(pdf_data, ~extract_table(.x)) |>
  unlist()

# First column of results
column1 <- table |>
  str_sub(1,63) |>
  str_trim()

# Extract sample text
column2 <- table |>
  str_sub(63) |>
  str_trim()

# Combine columns
table <- c(column1, column2) |>
  discard(~.x == "")

# All text
text <- table |>
  # str_extract(".*(?=\\s\\()")
  str_extract(".*(?=\\d{2}h\\d{2})") |>
  str_remove_all("\\(") |>
  str_trim()

# Extract site ID
site_id_column <- text |>
  str_extract("[:upper:]{2}\\s?\\d{2}") |>
  str_remove("\\s")

# Extract sample tag
tag <- text |>
  str_extract("(?<=([:upper:]{2}\\s?\\d{2}\\s)).*") |>
  str_replace("Field Blank", "Blank")

# Extract time
time <- table |>
  # str_extract("(?<=\\().*(?=\\))") |>
  str_extract("\\d{2}h\\d{2}") |>
  str_replace("h", ":")

# Extract result
result <- table |>
  str_extract("(?<=(\\s{5})).*$") |>
  str_trim() |>
  str_replace("None found", "ND")

# Combine all the data
tbl <- tibble(
  site_id = site_id_column,
  tag = tag,
  date = sample_date,
  time = time,
  analysis_completed = analysis_completed,
  sample_temp_c = sample_temp_c,
  enterococci_cfu_per_100ml = result,
  filename = filename
) |>
  arrange(time)

# Check data
tbl

# Copy to database
copy_to(con, tbl, name = "coastal", overwrite = TRUE)
```

### Alternative for sample sheets with multiple dates

```{r extract-pdf}
# Select the pdf that you want to import
path <- "../../Infinity/Coastal Water Quality - Documents/Shared Results/Camps Bay High-Frequency Sampling/02 Data/Infinity Environmental AD.151(CN).pdf"
filename <- str_remove(path, "../../Infinity/Coastal Water Quality - Documents/Shared Results/Camps Bay High-Frequency Sampling/02 Data/")

# Extract the pdf data
pdf_data <- pdf_text(path) |>
  str_split("\n")

# Select single page
page <- pdf_data |>
  pluck(1)

read_page <- function(page){
  
  # Extract the sample date
  sample_date <- page |>
    keep(~str_detect(.x, "Sample taken")) |>
    str_extract("\\d{1,2}\\s[:alpha:]{3,12}\\s\\d{4}") |>
    pluck(1) |>
    dmy()
  
  # Extract the analysis date
  analysis_completed <- page |>
    keep(~str_detect(.x, "Analysis completed")) |>
    str_extract("\\d{1,2}\\s[:alpha:]{3,12}\\s\\d{4}") |>
    pluck(1) |>
    dmy()
  
  # Extract the sample temperature
  sample_temp_c <- page |>
    keep(~str_detect(.x, "Sample temperature:")) |>
    str_extract("(?<=(Sample temperature:\\s))\\d{1,2}\\.\\d") |>
    pluck(1) |>
    as.numeric()
  
  # Extract tabular data
  table <- page |>
      head_while(~!str_detect(.x, "colony forming units")) |>
      tail_while(~!str_detect(.x, "Sample Description")) |>
      discard(~.x == "")
  
  # First column of results
  column1 <- table |>
    str_sub(1,63) |>
    str_trim()
  
  # Extract sample text
  column2 <- table |>
    str_sub(63) |>
    str_trim()
  
  # Combine columns
  combined <- c(column1, column2) |>
    discard(~.x == "")
  
  # All text
  text <- combined |>
    # str_extract(".*(?=\\s\\()")
    str_extract(".*(?=\\d{2}h\\d{2})") |>
    str_remove_all("\\(") |>
    str_trim()
  
  # Extract site ID
  site_id_column <- text |>
    str_extract("[:upper:]{2}\\s?\\d{2}") |>
    str_remove("\\s")
  
  # Extract sample tag
  tag <- text |>
    str_extract("(?<=([:upper:]{2}\\s?\\d{2}\\s)).*") |>
    str_replace("Field Blank", "Blank")
  
  # Extract time
  time <- combined |>
    # str_extract("(?<=\\().*(?=\\))") |>
    str_extract("\\d{2}h\\d{2}") |>
    str_replace("h", ":")
  
    # Extract result
  result <- combined |>
    str_extract("(?<=(\\s{5})).*$") |>
    str_trim() |>
    str_replace("None found", "ND")
  
  # Combine all the data
  tbl <- tibble(
    site_id = site_id_column,
    tag = tag,
    date = sample_date,
    time = time,
    analysis_completed = analysis_completed,
    sample_temp_c = sample_temp_c,
    enterococci_cfu_per_100ml = result,
    filename = filename
  ) |>
    arrange(time)
  
  return(tbl)
}

# Map all pages
tbl <- map_df(pdf_data, read_page)

# Check data
tbl

# Copy to database
copy_to(con, tbl |> filter(!is.na(site_id)), name = "coastal", overwrite = TRUE)
```

### Upload to database

```{sql, connection = con}
BEGIN;
```

```{sql connection = con}
SELECT * FROM coastal;
```

```{sql, connection = con}
WITH cte AS 
(SELECT
  site_id,
  tag,
  date,
  time::time,
  analysis_completed,
  sample_temp_c,
  enterococci_cfu_per_100ml,
  filename,
  'WLAB'::coastal.lab AS lab_code
FROM coastal)
INSERT INTO coastal.high_frequency_samples (site_id, tag, sample_date, sample_time, analysis_completed, sample_temp_c, enterococci_cfu_per_100ml, filename, lab_code)
SELECT * FROM cte;
```

```{sql, connection = con}
SELECT
  site_id, tag, sample_date, sample_time, enterococci_cfu_per_100ml, sample_temp_c, filename
FROM coastal.high_frequency_samples
WHERE sample_date = '2025-05-30'
ORDER BY sample_date, sample_time;
```

```{sql, connection = con}
ROLLBACK;
```

```{sql, connection = con}
COMMIT;
```

### Sample Metadata

```{r read-metadata}
metadata <- read_csv("../../Infinity/Coastal Water Quality - Documents/Shared Results/Camps Bay High-Frequency Sampling/01 Field Data & Chain of Custody/camps_bay_high_frequency.csv")

# Initial cleaning
metadata <- metadata |>
  rename(sample_date = "DATE", site_id = "SITE_ID", tag = "TAG", sample_time = "TIME", temperature_c = "TEMPERATURE", salinity_psu = "SALINITY") |>
  mutate(sample_date = case_when(
    (is.na(ymd(sample_date))) ~ dmy(sample_date),
    (is.na(dmy(sample_date))) ~ ymd(sample_date)
  )) |>
  mutate(tag = if_else(str_length(tag) == 0, NA, tag))
```

```{r copy-to-database}
copy_to(con, metadata, "metadata", temporary = TRUE, overwrite = TRUE)
```

```{sql, connection = con}
BEGIN;
```

```{sql, connection = con}
SELECT * FROM metadata;
```

```{sql, connection = con}
WITH final_cte AS
(WITH cte_metadata AS
(SELECT
  sample_date,
  site_id,
  CASE
    WHEN tag IS NULL THEN 'A'
    ELSE tag
  END AS tag,
  sample_time,
  CASE WHEN temperature_c = 'Not measured' THEN null ELSE temperature_c::numeric END AS temperature_c,
  CASE WHEN salinity_psu = 'Not measured' THEN null ELSE salinity_psu::numeric END AS salinity_psu
FROM metadata),
cte_samples AS
(SELECT
  sample_id,
  sample_date,
  sample_time,
  site_id,
  CASE
    WHEN tag IS NULL THEN 'A'
    ELSE tag
  END AS tag
FROM coastal.high_frequency_samples)

SELECT
  sample_id,
  temperature_c,
  salinity_psu
FROM cte_samples a
  LEFT JOIN cte_metadata b USING (site_id, sample_date, sample_time, tag))

UPDATE coastal.high_frequency_samples a
SET
  temperature_c = b.temperature_c,
  salinity_psu = b.salinity_psu
FROM final_cte b
WHERE a.sample_id = b.sample_id;
```
```{sql, connection = con}
SELECT site_id, tag, sample_date, sample_time, temperature_c, salinity_psu FROM coastal.high_frequency_samples
WHERE temperature_c IS NULL AND salinity_psu IS NULL AND tag IS NULL
  ORDER BY sample_date, sample_time, site_id, tag;
```

```{sql, connection = con}
SELECT * FROM coastal.high_frequency_samples WHERE site_id = 'CN41' AND sample_date = '2025-05-20' AND sample_time = '08:15';
```

```{sql, connection = con}
ROLLBACK;
```

```{sql, connection = con}
COMMIT;
```

```{sql, connection = con}
SELECT *
FROM coastal.high_frequency_samples a
  JOIN metadata b USING (sample_date, sample_time, site_id, tag)
```


## Add a single value

```{sql connection = con}
BEGIN;
```

```{sql connection = con}
SELECT * FROM coastal.high_frequency_samples;
```

```{sql connection = con}
INSERT INTO coastal.high_frequency_samples (site_id, tag, sample_date, sample_time, analysis_completed, sample_temp_c, enterococci_cfu_per_100ml, filename, lab_code)
VALUES
  ('CN41', 'A', '2025-05-27', '23:03:00', '2025-05-30', 3.6, '20', 'Infinity Environmental AD.145(CN).pdf', 'WLAB');
```

```{sql connection = con}
SELECT * FROM coastal.high_frequency_samples WHERE sample_date = '2025-05-27' AND enterococci_cfu_per_100ml = '20';
```

```{sql connection = con}
ROLLBACK;
```

```{sql connection = con}
COMMIT;
```

# Upload triplicate samples

## Upload triplicate samples from WALAB data sheet

```{r extract-pdf}
# Select the pdf that you want to import
path <- "../../Infinity/Coastal Water Quality - Documents/Shared Results/Triplicate Sampling/Infinity Environmental AD.178(FB).pdf"
filename <- str_remove(path, "../../Infinity/Coastal Water Quality - Documents/Shared Results/Triplicate Sampling/")

# Extract the pdf data
pdf_data <- pdf_text(path) |>
  str_split("\n")

# Extract the sample date
sample_date <- pdf_data |>
  unlist() |> 
  keep(~str_detect(.x, "Sample taken")) |>
  str_extract("\\d{1,2}\\s[:alpha:]{3,12}\\s\\d{4}") |>
  pluck(1) |>
  dmy()

# Extract the analysis date
analysis_completed <- pdf_data |>
  unlist() |> 
  keep(~str_detect(.x, "Analysis completed")) |>
  str_extract("\\d{1,2}\\s[:alpha:]{3,12}\\s\\d{4}") |>
  pluck(1) |>
  dmy()

# Extract the sample temperature
sample_temp_c <- pdf_data |>
  unlist() |> 
  keep(~str_detect(.x, "Sample temperature:")) |>
  str_extract("(?<=(Sample temperature:\\s))\\d{1,2}\\.\\d") |>
  pluck(1) |>
  as.numeric()

# Extract tabular data
extract_table <- function(page){
  page |>
    unlist() |> 
    head_while(~!str_detect(.x, "colony forming units")) |>
    tail_while(~!str_detect(.x, "Sample number")) |>
    discard(~.x == "") |>
    unlist()
}

# Extract table from all pages of pdf
table <- map(pdf_data, ~extract_table(.x)) |>
  unlist()

# Extract sample text
sample_text <- table |>
  str_sub(15,95) |>
  str_trim()

# Extract result
sample_result <- table |>
  str_sub(100) |>
  str_trim()

# Make a table with the extracted data
tbl <- tibble(
       text = sample_text,
       result = sample_result) |>
  mutate(
    sample_id = str_extract(text, "[:upper:]{2,3}\\d{2,3}[IAOWETC]?\\s?[ABCDEFGHI]?") |> str_remove("\\s"),
    site_id = str_extract(text, "[:upper:]{2,3}\\s?\\d{2}\\d?[AOIWETC]?") |> str_remove_all("\\s"),
    site_id = if_else(site_id %in% c("LB001", "FB001"), NA, site_id),
    sample_time = str_extract(text, "\\d{1,2}h\\d{2}") |> str_replace("h", ":"),
    sample_date = sample_date,
    analysis_completed = analysis_completed,
    sample_temp_c = sample_temp_c,
    filename = filename |> str_remove(path)
      ) |>
  select(-text) |>
  rename(enterococci_cfu_per_100ml = result) |>
  mutate(enterococci_cfu_per_100ml = str_replace(enterococci_cfu_per_100ml, "None found", "ND"))

# Check data
tbl

# Copy to database
copy_to(con, tbl, name = "coastal", overwrite = TRUE)
```

```{sql connection = con}
BEGIN;
```

```{sql connection = con}
SELECT * FROM coastal;
```

```{sql connection = con}
SELECT * FROM coastal.triplicate_results;
```

```{sql connection = con}
INSERT INTO coastal.triplicate_results (sample_id, site_id, sample_date, sample_time, analysis_completed, sample_temp_c, enterococci_cfu_per_100ml, filename, lab_code)
SELECT
  sample_id,
  site_id,
  sample_date,
  sample_time::time,
  analysis_completed,
  sample_temp_c,
  enterococci_cfu_per_100ml,
  filename,
  'WLAB'::coastal.lab AS lab_code
FROM coastal;
```

```{sql connection = con}
SELECT * FROM coastal.triplicate_results WHERE sample_date = '2025-07-01';
```

```{sql connection = con}
ROLLBACK;
```

```{sql connection = con}
COMMIT;
```

## Upload manually

```{r read-triplicate-data}
triplicates <- read_xlsx("../../Infinity/Coastal Water Quality - Documents/Shared Results/Triplicate Sampling/to_populate_202508.xlsx") |>
  mutate(sample_time = hms::as_hms(sample_time))
```

```{r assess-triplicate-data}
triplicates |>
  group_by(month = month(sample_date, label = TRUE), lab_code) |>
  count()

triplicates |>
  filter(lab_code == "SABS") |>
  group_by(sample_date) |>
  count()

# Have a look at the data
triplicates
```

```{r upload-data}
copy_to(con, triplicates, name = "triplicates", temporary = TRUE, overwrite = TRUE)
```

```{sql, connection = con}
BEGIN;
```

```{sql, connection = con}
SELECT * FROM triplicates;
```

```{sql, connection = con}
SELECT
  to_char(sample_date, 'month') AS month,
  lab_code,
  count(*)
FROM triplicates a
GROUP BY to_char(sample_date, 'month'), lab_code
ORDER BY month, lab_code;
```

```{sql, connection = con}
SELECT
  to_char(sample_date, 'month') AS month,
  lab_code,
  count(*)
FROM coastal.triplicate_results
GROUP BY to_char(sample_date, 'month'), lab_code
ORDER BY month, lab_code;
```

```{sql, connection = con}
INSERT INTO coastal.triplicate_results (sample_id, site_id, sample_date, sample_time, sample_temp_c, enterococci_cfu_per_100ml, filename, lab_code)
SELECT
  sample_id,
  site_id,
  sample_date,
  sample_time,
  sample_temp_c,
  enterococci_cfu_per_100ml,
  filename,
  lab_code::coastal.lab
FROM triplicates;
```

```{sql, connection = con}
SELECT
  to_char(sample_date, 'month') AS month,
  lab_code,
  count(*)
FROM coastal.triplicate_results
GROUP BY to_char(sample_date, 'month'), lab_code
ORDER BY to_char(sample_date, 'month'), lab_code;
```

```{sql, connection = con}
SELECT filename, enterococci_cfu_per_100ml FROM coastal.triplicate_results WHERE sample_date > '2025-08-01'
ORDER BY sample_date, lab_code;
```

```{sql, connection = con}
ROLLBACK;
```

```{sql, connection = con}
COMMIT;
```

# Upload historical data to database

## LIMS Data

```{r, fig.width = 7, fig.height = 10, dpi = 600}
lims_clean <- read_csv("02 Output Data/01 CSV/lims_data_clean.csv")

lims_clean |>
  arrange(sample_date) |>
  mutate(sample_date = date(sample_date)) |>
  group_by(site_id, month = floor_date(sample_date, "month") |> as.character() |> fct_inorder()) |>
  count() |>
  ggplot(aes(x = month, y = n)) +
  geom_col() +
  facet_wrap(facets = vars(site_id))

# Check the distribution of the data
lims_clean |>
  ggplot(aes(x = numeric_value)) +
  geom_density()

# Check the distribution of the data without outliers
lims_clean |>
  filter(numeric_value < 25000) |>
  ggplot(aes(x = numeric_value)) +
  geom_density()

# Do we remove the data from 2022 onwards?
lims_clean |>
  group_by(year = year(sample_date), month = month(sample_date, label = TRUE)) |>
  count() |>
  ggplot(aes(x = month, y = n)) +
  geom_col() +
  facet_wrap(facets = vars(year))

# LIMS data are ready for upload as soon as the sites are uploaded to database
lims_clean <- lims_clean |>
  filter(sample_date < "2022-04-01")

copy_to(con, lims_clean, name = "lims", temporary = TRUE, overwrite = TRUE)
```

```{sql connection = con}
BEGIN;
```

```{sql connection = con}
SELECT * FROM lims;
```

```{sql connection = con}
WITH cte AS (
SELECT
  site_id,
  sample_date,
  censored_value
FROM lims)
INSERT INTO coastal.results (site_id, sample_date, enterococci_cfu_per_100ml, lab_code, monitoring_group)
SELECT
  site_id,
  sample_date,
  censored_value,
  'SSVC'::coastal.lab,
  'routine'::coastal.monitoring_group
FROM cte;
```

```{sql connection = con}
SELECT
  site_id,
  count(*)
FROM coastal.results
GROUP BY site_id
ORDER BY site_id;
```

```{sql connection = con}
BEGIN;
```

```{sql connection = con}
ROLLBACK;
```

```{sql connection = con}
COMMIT;
```


## Blue Flag Data

```{r}
blue_flag <- read_csv("02 Output Data/blue_flag_clean.csv")

blue_flag |>
  distinct(site_id) # 13 sites

blue_flag |>
  summary()

blue_flag |>
  mutate(sample_date = date(sample_date)) |>
  group_by(site_id, month = floor_date(sample_date, "month")) |>
  count() |>
  ggplot(aes(x = month, y = n, facet = site_id)) +
  geom_col() +
  scale_x_date(minor_breaks = "1 year") +
  facet_wrap(facets = vars(site_id))

# Which sample is by itself in 2011?
blue_flag |>
  filter(sample_date < "2012-01-01")

# It is a type, supposed to be 2021
blue_flag <- blue_flag |>
  mutate(sample_date = if_else(sample_date == ymd("2011-12-08"), ymd("2021-12-08"), sample_date))

# Check the distribution of the data again
blue_flag |>
  mutate(numeric_value = if_else(str_detect(censored_value, ">"), censored_value |> str_remove(">") |> as.numeric(), censored_value |> as.numeric())) |>
  ggplot(aes(x = numeric_value)) +
  geom_density()

# Check the distribution of the data again
blue_flag |>
  mutate(numeric_value = if_else(str_detect(censored_value, ">"), censored_value |> str_remove(">") |> as.numeric(), censored_value |> as.numeric())) |>
  filter(numeric_value < 3000) |> 
  ggplot(aes(x = numeric_value)) +
  geom_density()

blue_flag <- blue_flag |>
  filter(!is.na(censored_value))

copy_to(con, blue_flag, name = "blue_flag", temporary = TRUE, overwrite = TRUE)

# Blue Flag data are ready to be uploaded once the LIMS sites are uploaded to database
```

```{sql connection = con}
BEGIN;
```

```{sql connection = con}
SELECT count(*) FROM blue_flag;
```

```{sql connection = con}
WITH cte AS
(SELECT
  site_id,
  sample_date,
  censored_value,
  file,
  'SABS'::coastal.lab,
  'blue_flag'::coastal.monitoring_group
FROM blue_flag)
INSERT INTO coastal.results (site_id, sample_date, enterococci_cfu_per_100ml, filename, lab_code, monitoring_group)
SELECT * FROM cte;
```

```{sql connection = con}
SELECT count(*)
FROM coastal.results
WHERE monitoring_group = 'blue_flag';
```

```{sql connection = con}
ROLLBACK;
```

```{sql connection = con}
COMMIT;
```

## SABS Routine Data

```{r read-sabs-data}
sabs_clean <- read_csv("02 Output Data/01 CSV/sabs_data_clean.csv")

# Check unique sites
sabs_clean |>
  distinct(site_id) |>
  arrange(site_id)

# Sites that need to be changed
sabs_clean <- sabs_clean |>
  mutate(site_id = case_when(
    site_id == "CS12" ~ "CS45",
    site_id == "ICS03" & sample_date > "2024-04-30" ~ "ICS14",
    .default = site_id
    ))

# Structure of the data
glimpse(sabs_clean)

# Summary of the data
summary(sabs_clean)

# Sites
sabs_clean |>
  distinct(site_id) |>
  arrange(site_id)

# Check the sample dates
sabs_clean |>
  mutate(sample_date = date(sample_date)) |>
  mutate(month = floor_date(sample_date, "month") |> as.character() |> fct_inorder()) |>
  group_by(site_id, month) |>
  count() |>
  ggplot(aes(x = month, y = n)) +
  geom_col() +
  facet_wrap(facets = vars(site_id)) +
  theme(axis.text.x = element_text(angle = 90))

# Why is CN04 by itself?
sabs_clean |>
  filter(site_id == "CN04")

# Check the distribution of the data again
sabs_clean |>
  mutate(numeric_value = case_when(
    censored_value |> str_detect(">") ~ censored_value |> str_remove(">") |> as.numeric(),
    censored_value |> str_detect("ND") ~ 0,
    .default = censored_value |> as.numeric()
  )) |>
  ggplot(aes(x = numeric_value)) +
  geom_density()

# Check the high and low values
sabs_clean |>
  mutate(numeric_value = case_when(
    censored_value |> str_detect(">") ~ censored_value |> str_remove(">") |> as.numeric(),
    censored_value |> str_detect("ND") ~ 0,
    .default = censored_value |> as.numeric()
  )) |>
  arrange(-numeric_value)

# SABS data are ready for upload once the SABS sites have been uploaded to database

copy_to(con, sabs_clean, name = "sabs_clean", temporary = TRUE, overwrite = TRUE)
```

```{sql connection = con}
BEGIN;
```

```{sql connection = con}
SELECT
  count(*)
FROM sabs_clean;
```

```{sql connection = con}
WITH cte AS (
SELECT
  site_id,
  sample_date,
  censored_value,
  filename,
  'SABS'::coastal.lab,
  'routine'::coastal.monitoring_group
FROM sabs_clean)
INSERT INTO coastal.results (site_id, sample_date, enterococci_cfu_per_100ml, filename, lab_code, monitoring_group)
SELECT * FROM cte;
```

```{sql connection = con}
SELECT * FROM coastal.results WHERE monitoring_group = 'routine' AND lab_code = 'SABS';
```

```{sql connection = con}
ROLLBACK;
```

```{sql connection = con}
COMMIT;
```

## SABS Daily Samples

```{r read-sabs-dailies}
sabs_daily_clean <- read_csv("02 Output Data/sabs_daily_clean.csv")

sabs_daily_clean |>
  group_by(sample_date, site_id, enterococci_cfu_per_100ml) |>
  count() |>
  arrange(-n)

sabs_daily_clean |>
  filter(sample_date == "2024-08-30")

# Remove Strandfontein data from Atlantic data
sabs_daily_clean <- sabs_daily_clean |>
  filter(!(site_description |> str_detect("Strandf")))

# Plot the data per day
sabs_daily_clean |>
  mutate(sample_date = date(sample_date)) |> 
  mutate(month = floor_date(sample_date, "month")) |>
  group_by(site_id, month) |>
  ggplot(aes(x = month)) +
  geom_histogram(stat = "count") +
  facet_wrap(facets = vars(site_id))

# Plot the distribution of the data
sabs_daily_clean |>
  mutate(numeric_value = case_when(
    enterococci_cfu_per_100ml |> str_detect(">") ~ enterococci_cfu_per_100ml |> str_remove(">") |> as.numeric(),
    enterococci_cfu_per_100ml |> str_detect("ND") ~ 0,
    .default = enterococci_cfu_per_100ml |> as.numeric()
  )) |>
  ggplot(aes(x = numeric_value)) +
  geom_density()

sabs_daily_clean |>
  mutate(numeric_value = case_when(
    enterococci_cfu_per_100ml |> str_detect(">") ~ enterococci_cfu_per_100ml |> str_remove(">") |> as.numeric(),
    enterococci_cfu_per_100ml |> str_detect("ND") ~ 0,
    .default = enterococci_cfu_per_100ml |> as.numeric()
  )) |>
  arrange(-numeric_value)

# Daily SABS data are ready to upload as soon as ICS12 is uploaded as a site

copy_to(con, sabs_daily_clean, name = "sabs_daily_clean", temporary = TRUE, overwrite = TRUE)
```

```{sql connection = con}
BEGIN;
```

```{sql connection = con}
WITH cte AS
(SELECT
  site_id,
  sample_date,
  sample_time,
  enterococci_cfu_per_100ml,
  'SABS'::coastal.lab,
  'daily'::coastal.monitoring_group
FROM sabs_daily_clean)
INSERT INTO coastal.results (site_id, sample_date, sample_time, enterococci_cfu_per_100ml, lab_code, monitoring_group)
SELECT * FROM cte;
```

```{sql connection = con}
SELECT * FROM coastal.results WHERE lab_code = 'SABS' AND monitoring_group = 'daily';
```

```{sql connection = con}
ROLLBACK;
```

```{sql connection = con}
COMMIT;
```


## WALAB Atlantic Daily

```{r}
daily_clean_atlantic <- read_csv("02 Output Data/daily_clean_atlantic.csv")

daily_clean_atlantic |>
  distinct(site_id)

daily_clean_atlantic |>
  group_by(site_id, sample_date) |>
  count() |>
  arrange(-n)

daily_clean_atlantic |>
  mutate(sample_date = date(sample_date)) |> 
  mutate(month = floor_date(sample_date, "month")) |>
  group_by(site_id, month) |>
  ggplot(aes(x = month)) +
  geom_histogram(stat = "count") +
  facet_wrap(facets = vars(site_id))

daily_clean_atlantic |>
  mutate(numeric_value = case_when(
    enterococci_cfu_per_100ml |> str_detect(">") ~ enterococci_cfu_per_100ml |> str_remove(">") |> as.numeric(),
    enterococci_cfu_per_100ml |> str_detect("ND") ~ 0,
    .default = enterococci_cfu_per_100ml |> as.numeric()
  )) |>
  ggplot(aes(x = numeric_value)) +
  geom_density()

daily_clean_atlantic |>
  mutate(numeric_value = case_when(
    enterococci_cfu_per_100ml |> str_detect(">") ~ enterococci_cfu_per_100ml |> str_remove(">") |> as.numeric(),
    enterococci_cfu_per_100ml |> str_detect("ND") ~ 0,
    .default = enterococci_cfu_per_100ml |> as.numeric()
  )) |>
  arrange(-numeric_value)

# These data are ready to upload as soon as ICS10 and ICS15 are uploaded

copy_to(con, daily_clean_atlantic, name = "daily_atlantic", temporary = TRUE, overwrite = TRUE)
```

```{sql connection = con}
BEGIN;
```

```{sql connection = con}
WITH cte AS (SELECT
  site_id,
  sample_date,
  sample_time,
  analysis_completed,
  enterococci_cfu_per_100ml,
  sample_temp_c,
  filename,
  'WLAB'::coastal.lab,
  'daily'::coastal.monitoring_group
FROM daily_atlantic)
INSERT INTO coastal.results (site_id, sample_date, sample_time, analysis_completed, enterococci_cfu_per_100ml, sample_temp_c, filename, lab_code, monitoring_group)
SELECT * FROM cte;
```

```{sql connection = con}
SELECT * FROM coastal.results WHERE lab_code = 'WLAB' AND monitoring_group = 'daily';
```

```{sql connection = con}
ROLLBACK;
```

```{sql connection = con}
COMMIT;
```

## WALAB Strand Daily

```{r read-strand-daily}
strand_daily_clean <- read_csv("02 Output Data/daily_clean_strand.csv")

# Reorganize columns
strand_daily_clean |>
  select(site_id, sample_date, sample_time, analysis_completed, sample_temp_c, enterococci_cfu_per_100ml, filename)

# Check for duplicate data
strand_daily_clean |>
  group_by(sample_date, site_id) |>
  count() |>
  arrange(-n)

strand_daily_clean |>
  filter(sample_date == "2025-02-13")

# Change the names of the sites
strand_daily_clean <- strand_daily_clean |>
  mutate(site_id = case_when(
    site_id == "CS30"~ "XCS34",
    site_id == "CS31" ~ "XCS26",
    .default = site_id
  ))

strand_daily_clean |>
  mutate(sample_date = date(sample_date)) |> 
  mutate(month = floor_date(sample_date, "month")) |>
  group_by(site_id, month) |>
  ggplot(aes(x = month)) +
  geom_histogram(stat = "count") +
  facet_wrap(facets = vars(site_id))

strand_daily_clean |>
  mutate(numeric_value = case_when(
    enterococci_cfu_per_100ml |> str_detect(">") ~ enterococci_cfu_per_100ml |> str_remove(">") |> as.numeric(),
    enterococci_cfu_per_100ml |> str_detect("ND") ~ 0,
    .default = enterococci_cfu_per_100ml |> as.numeric()
  )) |>
  ggplot(aes(x = numeric_value)) +
  geom_density()

strand_daily_clean |>
  mutate(numeric_value = case_when(
    enterococci_cfu_per_100ml |> str_detect(">") ~ enterococci_cfu_per_100ml |> str_remove(">") |> as.numeric(),
    enterococci_cfu_per_100ml |> str_detect("ND") ~ 0,
    .default = enterococci_cfu_per_100ml |> as.numeric()
  )) |>
  arrange(-numeric_value)

# These data are ready for upload

copy_to(con, strand_daily_clean, name = "strand_daily", temporary = TRUE, overwrite = TRUE)
```

```{sql connection = con}
BEGIN;
```

```{sql connection = con}
WITH cte AS 
(SELECT
  site_id,
  sample_date,
  sample_time,
  analysis_completed,
  enterococci_cfu_per_100ml,
  sample_temp_c,
  filename,
  'WLAB'::coastal.lab,
  'daily'::coastal.monitoring_group
FROM strand_daily)
INSERT INTO coastal.results (site_id, sample_date, sample_time, analysis_completed, enterococci_cfu_per_100ml, sample_temp_c, filename, lab_code, monitoring_group)
SELECT * FROM cte;
```

```{sql connection = con}
SELECT * FROM coastal.results WHERE lab_code = 'WLAB' AND monitoring_group = 'daily';
```

```{sql connection = con}
SELECT site_id, count(*) FROM coastal.results GROUP BY site_id ORDER BY site_id;
```

```{sql connection = con}
ROLLBACK;
```

```{sql connection = con}
COMMIT;
```

```{r}

```

# Extract data from scanned pdfs

```{r exctract-scanned-data}
pdf_data <- pdf_convert("../../Infinity/Coastal Water Quality - Documents/Shared Results/00_Admin and old programmes/Weekly Coastal WQ/2023-10-03/K1237.pdf", dpi = 600)

eng <- tesseract(options = list(tessedit_pageseg_mode = 1))

pdf_data |>
  ocr(engine = eng) |>
  str_split("\n")

extracted <- tibble(
  filename_long = list.files("../../Infinity/Coastal Water Quality - Documents/Shared Results/00_Admin and old programmes/Weekly Coastal WQ/2023-10-03/", pattern = "*.pdf", full.names = T),
  filename_short = list.files("../../Infinity/Coastal Water Quality - Documents/Shared Results/00_Admin and old programmes/Weekly Coastal WQ/2023-10-03/", pattern = "*.pdf")
) |>
  mutate(pdf_image = map(filename_long, ~pdf_convert(.x, dpi = 600))) |>
  mutate(text = map(pdf_image, ~ocr(.x, engine = eng) |> str_split("\n")))

extracted |>
  mutate(text = map(text, ~unlist(.x))) |>
  mutate(sample_date = map(text, ~keep(.x, str_detect(.x, "Date sampled:")))) |>
  mutate(sample_information = map(text, ~keep(.x, str_detect(.x, "Temperature on arrival")))) |>
  mutate(results = )
  pull(sample_information)
```
# Upload ad-hoc samples

```{r data-import}
tibble(
  filename_short = list.files("../../Infinity/Coastal Water Quality - Documents/Shared Results/Saunders Rocks/", pattern = "*.pdf"),
  filename_long = list.files("../../Infinity/Coastal Water Quality - Documents/Shared Results/Saunders Rocks/", pattern = "*.pdf", full.names = T)
) |>
  mutate(pdf_data = map(filename_long, ~ pdf_text(.x) |>
    str_split("\n") |>
    unlist())) |>
  mutate(sample_date = map(pdf_data, ~keep(.x, ~str_detect(.x, "Sample taken")) |> str_remove("\\*Sample taken:") |> str_trim() |> dmy())) |>
  mutate(analysis_completed = map(pdf_data, ~keep(.x, ~str_detect(.x, "Analysis completed")) |> str_remove("Analysis completed:") |> str_trim() |> dmy())) |>
  mutate(sample_temp_c = map(pdf_data, ~keep(.x, ~str_detect(.x, "Sample temperature")) |> str_remove("Sample temperature:") |> str_trim() |> str_remove("ºC") |> as.numeric())) |>
  mutate(data = map(pdf_data, ~{
    .x |> tail_while(~!str_detect(.x, "Sample number")) |> head_while(~!str_detect(.x, "colony forming")) |> keep(~str_length(.x) > 0)
  })) |>
  mutate(site_id = map(data, ~str_extract(.x, "CN16\\s[BIO]") |> str_replace("\\s", ""))) |>
  mutate(sample_time = map(data, ~str_extract(.x, "\\d{2}h\\d{2}") |> str_replace("h", ":"))) |>
  mutate(censored_value = map(data, ~str_sub(.x, 35) |> str_trim() |> str_split("\\s{5,}"))) |>
  unnest(sample_date, analysis_completed, sample_temp_c, site_id, sample_time, censored_value) |>
  unnest_wider(censored_value, names_sep = "_") |>
  rename("Enterococci" = censored_value_1, "Escherichia coli" = censored_value_2) |>
  pivot_longer(cols = c("Enterococci", "Escherichia coli"), names_to = "parameter", values_to = "censored_value") |>
  select(site_id, sample_date, sample_time, analysis_completed, sample_temp_c, parameter, censored_value, filename_short) |>
  mutate(censored_value = str_replace(censored_value, "None found", "ND")) |>
  filter(!is.na(censored_value)) |>
  
  # Remove the data that have been uploaded to the CWQ database
  filter(site_id == "CN16B") |>
  
  # Upload to database
  copy_to(dest = con, name = "saunders", temporary = T, overwrite = T)
```

```{sql, connection = con}
BEGIN;
```

```{sql, connection = con}
SELECT
  site_id,
  sample_date,
  sample_time,
  analysis_completed,
  sample_temp_c,
  parameter,
  censored_value,
  'cfu per 100 mL' AS unit,
  filename_short
FROM saunders;
```

```{sql, connection = con}
INSERT INTO coastal.results_adhoc(description, sample_date, sample_time, analysis_completed, sample_temp_c, parameter, censored_value, unit, filename, lab_code)
SELECT
  site_id,
  sample_date,
  sample_time::time,
  analysis_completed,
  sample_temp_c,
  parameter,
  censored_value,
  'cfu per 100 mL' AS unit,
  filename_short,
  'WLAB' AS lab_code
FROM saunders;
```

```{sql, connection = con}
SELECT
  filename,
  description,
  parameter,
  censored_value
FROM coastal.results_adhoc
ORDER BY random()
LIMIT 5;
```

```{sql, connection = con}
SELECT * FROM coastal.results_adhoc;
```

```{sql, connection = con}
ROLLBACK;
```

```{sql, connection = con}
COMMIT;
```

## Find Simons Town diving school and Woolies paddle pool samples

```{r extract-data}
tibble(
  filename_long = list.files("../../Infinity/Coastal Water Quality - Documents/Shared Results/SSB CMB Monitoring/", pattern = "*.pdf", full.names = T) |> keep(~str_detect(.x, "CWQ")),
  filename_short = list.files("../../Infinity/Coastal Water Quality - Documents/Shared Results/SSB CMB Monitoring/", pattern = "*.pdf") |> keep(~str_detect(.x, "CWQ"))
) |>
  mutate(pdf_data = map(filename_long, ~pdf_text(.x) |> str_split("\n"))) |>
  mutate(data = map(pdf_data, ~map(.x, ~{
    .x |>
      head_while(~!str_detect(.x, "colony")) |>
      tail_while(~!str_detect(.x, "Sample number")) |>
      keep(~str_length(.x)>0)
  }) |> unlist())) |>
  arrange(filename_short) |>
  unnest(data) |>
  select(filename_short, data) |>
  mutate(sample_date = str_extract(filename_short, "\\d{1,2}\\.\\d{2}\\.\\d{4}") |> dmy()) |>
  filter(sample_date |> between(ymd("2025-09-01"), ymd("2025-11-01"))) |>
  filter(data |> str_to_lower() |> str_detect("(simon)|(driving)|(diving)|(wool)|(adhoc)|(ad hoc)"))
  
```