---
title: "Import Coastal Water Quality Data"
author: "Francois van Schalkwyk"
date: "2025-03-19"
output: html_document
---

# Workspace Set-Up

Make sure that you are working in the outfalls project, found in the working directory.

## Set working directory for all code chunks to project root directory

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
```

## Load required packages

```{r message = FALSE}
library(tidyverse)
library(dbplyr)
library(DBI)
library(pdftools)
library(readxl)
```

## Database Connection

```{r db connection}
# Connect to the Postgres database
con <- dbConnect(RPostgres::Postgres(),
  host = "infinity.cdmqm0mu0qf8.eu-north-1.rds.amazonaws.com",
  port = 5432,
  user = rstudioapi::askForPassword(prompt = "Username: "),
  password = rstudioapi::askForPassword(),
  dbname = "infinity"
)
```

```{r}
dbGetInfo(con)
```

# Data Import

## Check which pdf files have not yet been imported

```{r not-yet-imported}
# List of files in folder
files_list <- list.files("../../Infinity/Coastal Water Quality - Documents/Shared Results/SSB CMB Monitoring/", pattern = "*.pdf")

extract_sample_date <- function(filename){
  sample_date <- pdf_text(paste("../../Infinity/Coastal Water Quality - Documents/Shared Results/SSB CMB Monitoring/", filename, sep = "")) |>
    str_split("\\n") |>
    unlist() |>
    keep(~str_detect(.x, "Sample taken")) |>
    str_extract("\\d{1,2}\\s[:alpha:]{3,12}\\s\\d{4}") |>
    pluck(1) |>
    dmy()
  
  tibble(filename = filename, sample_date = sample_date)
}

# Map the function across the list of files in the directory
files <- map_df(files_list, ~extract_sample_date(.x))

# Retrieve a list of sample dates from the results table in database
database <- tbl(con, I("coastal.results")) |>
  distinct(sample_date) |>
  collect()

# Check which files are not yet in database
files |>
  left_join(database, by = c("sample_date" = "sample_date"), keep = TRUE) |>
  filter(is.na(sample_date.y))
```

## Extract data from pdf

```{r extract-pdf}
# Select the pdf that you want to import
path <- "../../Infinity/Coastal Water Quality - Documents/Shared Results/SSB CMB Monitoring/CWQ_56(25.03.2025).pdf"
filename = str_remove(path, "../../Infinity/Coastal Water Quality - Documents/Shared Results/SSB CMB Monitoring/")

# Extract the pdf data
pdf_data <- pdf_text(path) |>
  str_split("\n")

# Extract the sample date
sample_date <- pdf_data |>
  unlist() |> 
  keep(~str_detect(.x, "Sample taken")) |>
  str_extract("\\d{1,2}\\s[:alpha:]{3,12}\\s\\d{4}") |>
  pluck(1) |>
  dmy()

# Extract the analysis date
analysis_completed <- pdf_data |>
  unlist() |> 
  keep(~str_detect(.x, "Analysis completed")) |>
  str_extract("\\d{1,2}\\s[:alpha:]{3,12}\\s\\d{4}") |>
  pluck(1) |>
  dmy()

# Extract the sample temperature
sample_temp_c <- pdf_data |>
  unlist() |> 
  keep(~str_detect(.x, "Sample temperature:")) |>
  str_extract("(?<=(Sample temperature:\\s))\\d{1,2}\\.\\d") |>
  pluck(1) |>
  as.numeric()

# Extract tabular data
extract_table <- function(page){
  page |>
    unlist() |> 
    head_while(~!str_detect(.x, "colony forming units")) |>
    tail_while(~!str_detect(.x, "Sample number")) |>
    discard(~.x == "") |>
    unlist()
}

# Extract table from all pages of pdf
table <- map(pdf_data, ~extract_table(.x)) |>
  unlist()

# Extract sample number
sample_number <- table |>
  str_sub(5,15) |>
  str_trim()

# Extract sample text
sample_text <- table |>
  str_sub(19,95) |>
  str_trim()

# Extract result
sample_result <- table |>
  str_sub(100) |>
  str_trim()

# Make a table with the extracted data
tbl <- tibble(number = sample_number,
       text = sample_text,
       result = sample_result) |> 
  mutate(number = if_else(number == "", NA, number)) |>
  fill(number, .direction = "down") |> 
  group_by(number) |>
  summarise(text = str_c(text, collapse = ""), result = first(result)) |>
  select(text, result) |>
  mutate(
    site_id = str_extract(text, "[:upper:]{2,3}\\s?\\d{2}\\d?[AOIWETC]?") |> str_remove_all("\\s"),
    sample_time = str_extract(text, "\\d{1,2}h\\d{2}") |> str_replace("h", ":"),
    sample_date = sample_date,
    analysis_completed = analysis_completed,
    sample_temp_c = sample_temp_c,
    filename = filename
    ) |>
  select(-text) |>
  rename(enterococci_cfu_per_100ml = result) |>
  mutate(site_id = case_when(
    str_detect(site_id, "\\d{3}") & str_detect(site_id, "1$") ~ str_replace(site_id, "1$", "I"),
    str_detect(site_id, "\\d{3}") & str_detect(site_id, "0$") ~ str_replace(site_id, "0$", "O"),
    .default = site_id
  )) |>
  mutate(enterococci_cfu_per_100ml = str_replace(enterococci_cfu_per_100ml, "None found", "ND"))

# Copy to database
copy_to(con, tbl, name = "coastal", overwrite = TRUE)
```

## Upload to database

```{sql, connection = con}
BEGIN;
```

```{sql, connection = con}
WITH cte AS 
(SELECT
  site_id,
  sample_date,
  sample_time::time,
  analysis_completed,
  sample_temp_c,
  enterococci_cfu_per_100ml,
  filename
FROM coastal)
INSERT INTO coastal.results (site_id, sample_date, sample_time, analysis_completed, sample_temp_c, enterococci_cfu_per_100ml, filename)
SELECT * FROM cte;
```

```{sql, connection = con}
SELECT
  site_id, sample_date, sample_time, enterococci_cfu_per_100ml
FROM coastal.results
WHERE sample_date = '2025-03-25'
```

```{sql, connection = con}
ROLLBACK;
```

```{sql, connection = con}
COMMIT;
```

# Historical Data

```{r list-files}
# List the files in the directory
path <- "01 Input Data/Coastal Water Quality Data/"
files <- list.files(path = path, pattern = "*.xls*")
full_path <- paste(path, files, sep = "")
```

```{r read-excel-function-copy}
# Create function for extracting data and populating table
read_bacteria_data <- function(file, sheet){
  # Extract filename
  filename <- file |> str_remove("01 Input Data/Coastal Water Quality Data/")
  
  # Read Ecoli data
  data <- read_excel(file,
                      range = "A1:B1000",
                      sheet = sheet,
                      col_names = c("date", "value_cfu_per_100ml"),
                      col_types = c("date", "numeric"))
  
  # If empty tibble, create new empty tibble
  if (nrow(data) == 0) {
    data <- tibble(date = date(), value_cfu_per_100ml = numeric())
    data <- add_case(data, date = NA, value_cfu_per_100ml = NA) |>
      mutate(date = date(date))
  }
  
  results <- data |>
    slice(-1) |>
    filter(!is.na(value_cfu_per_100ml)) |>
    mutate(
      date = date(date),
      file = filename
      )

  return(results)
}
```

```{r run-function}
# Run the function with all files for E. coli
ecoli <- str_c(path, files) |>
  map_df(~read_bacteria_data(.x, 2))

# Run the function for faecal streptococci
faecal <- str_c(path, files) |>
  map_df(~read_bacteria_data(.x, 3))
```

```{r summary-statistics}
# Check summary statistics for ecoli
ecoli |>
  group_by(file) |>
  arrange(file) |>
  summarise(
    min_date = min(date),
    max_date = max(date),
    n = sum(!is.na(value_cfu_per_100ml)),
    min = min(value_cfu_per_100ml, na.rm = TRUE),
    max = max(value_cfu_per_100ml, na.rm = TRUE)
    )

# Check summary statistics for faecal streptococci
faecal |>
  group_by(file) |>
  arrange(file) |>
  summarise(
    min_date = min(date),
    max_date = max(date),
    n = sum(!is.na(value_cfu_per_100ml)),
    min = min(value_cfu_per_100ml, na.rm = TRUE),
    max = max(value_cfu_per_100ml, na.rm = TRUE)
    )
```

```{r intensive-cleaning}
# For each file, calculate the gap between the most recent and next most recent file. If the value is 1, remove that record
ecoli |>
  group_by(file) |>
  mutate(gap = date - lag(date)) |>
  filter(!(gap > "100 days" & value_cfu_per_100ml == 1) & file != "64_Muizenberg_Sufing_area-In_Line_with_Bathing_area_(CS34) SSB and CMB.xlsm") |>
  ggplot(aes(x = date, y = value_cfu_per_100ml, colour = file)) +
  geom_point() +
  theme(legend.position = "none") +
  coord_cartesian(xlim = c(ymd("2024-01-01"), ymd("2025-07-01")), ylim = c(0, 250))

# Clean data
ecoli <- ecoli |>
  group_by(file) |>
  mutate(gap = date - lag(date)) |>
  filter(!(gap > "100 days" & value_cfu_per_100ml == 1)) |>
  filter(!(file == "56_Fish_Hoek-Corner_of_the_Beach,_at_Jager_Walk_(CS35) CMB and SSB.xlsm" & date > "2024-02-21" & value_cfu_per_100ml == 1)) |> 
  filter(!(file == "56_Fish_Hoek-Corner_of_the_Beach,_at_Jager_Walk_(CS35).xlsm" & date > "2024-02-21" & value_cfu_per_100ml == 1)) |>
  filter(!(file == "56_Fish_Hoek_lifesaving_club_(CS41).xlsm" & date > "2024-02-21" & value_cfu_per_100ml == 1)) |>
  filter(!(file == "57_Woolleys_Tidal_Pool_(CS42).xlsm" & date >= "2024-02-07" & round(value_cfu_per_100ml, 2) == 3.33)) |>
  filter(!(file == "59_Kalk_Bay_Tidal_Pool_Inside_(CS02).xlsm" & date > "2024-02-21" & value_cfu_per_100ml == 1)) |>
  filter(!(file == "63_Muizenberg_Pavilion_(CS16).xlsm" & date >= "2024-02-21" & value_cfu_per_100ml == 31)) |>
  filter(!(file == "64_Muizenberg_Sufing_area-In_Line_with_Bathing_area_(CS34) SSB and CMB.xlsm" & date >= "2024-04-01" & value_cfu_per_100ml == 88)) |>
  filter(!(file == "64_Muizenberg_Sufing_area-In_Line_with_Bathing_area_(CS34).xlsm" & date >= "2024-04-01" & value_cfu_per_100ml == 88)) |>
  filter(!(file == "39_Cosy_Bay_(CN39).xlsm" & date >= "2024-10-31")) |>
  filter(!(file == "39_Oudekraal_(XCN09).xlsm" & date >= "2024-10-31")) |>
  filter(!(file == "466__Millers_Point_tidal_pool_(CS37).xlsm")) |>
  select(-gap)
```

Plotting the data for ecoli shows that there are many horizontal solid lines which show data that are exactly the same at a very high frequency. Having a look at the data shows that there are some sheets where a single value is repeated daily for a long time. Since the values in the rest of the data sheet are often weekly and vary, as can be seen by the random scatter on the plots, these data are certainly not indicative of true data and need to be removed. 

The removal of these data should result in a random scatter of points on the plot.

```{r plot-data}
# Plot the data
ecoli |>
  ggplot(aes(x = date, y = value_cfu_per_100ml, colour = file)) +
  geom_point() +
  theme(legend.position = "none") +
  coord_cartesian(xlim = c(ymd("2022-01-01"), ymd("2025-06-01")))
```

After the removal of the lines in the data, there are still some streaks but at much lower frequencies. These are likely to represent censored values and will be dealt with later.

```{r faecal-plot}
faecal |>
  ggplot(aes(x = date, y = value_cfu_per_100ml, colour = file)) +
  geom_point() +
  theme(legend.position = "none") +
  coord_cartesian(xlim = c(ymd("2023-01-01"), ymd("2025-06-01")), ylim = c(0, 5000))
```

The faecal streptococci data don't seem to have the same solid lines that the E. coli data had. There are also some streaks but these streaks occur at frequencies that can be reasonably expected from weekly sampling. These are also likely to be due to censored values, which will be dealt with in due course. 

```{r remove-duplicates}
# Remove duplicate values
ecoli <- ecoli |>
  mutate(
    site_id = str_extract(file, "[:upper:]{2,3}\\d{2}[:upper:]?"),
    full = str_detect(file, "SSB|CMB")
  ) |>
  group_by(date, site_id, full, value_cfu_per_100ml) |>
  slice(1) |> 
  arrange(full, .by_group = TRUE) |>
  ungroup(full) |> 
  slice_tail(n = 1) |>
  ungroup()

faecal <- faecal |>
  mutate(
    site_id = str_extract(file, "[:upper:]{2,3}\\d{2}[:upper:]?"),
    full = str_detect(file, "SSB|CMB")
  ) |>
  group_by(date, site_id, full, value_cfu_per_100ml) |>
  slice(1) |>
  arrange(full, .by_group = TRUE) |>
  ungroup(full) |>
  slice_tail(n = 1) |>
  ungroup()
```

There seem to be some duplicate values in the data. Some of these values naturally duplicated because of the duplication of data in the CMB and SSB duplicate sheets. Values that overlap simply because they appear in both sheets can reasonably be removed. Other values that have the same result for the same site on the same day can reasonably be removed only if there is no precedent for multiple samples on the same day. There are instances where multiple samples are taken on the same day, and therefore this needs to be done carefully so that results are not removed that simply happen to have the same value on the same day for the same site. 

# Replace numeric values with censored equivalents

```{r censored-values}
ecoli |>
  ungroup() |>
  arrange(value_cfu_per_100ml)

# Plot the data to see where streaks occur that may indicate the presence of censored values
ecoli |>
  filter(value_cfu_per_100ml < 15 & value_cfu_per_100ml != 1/3 & value_cfu_per_100ml != 10/3) |> 
  ggplot(aes(x = date, y = value_cfu_per_100ml, colour = site_id)) +
  geom_point() +
  scale_y_continuous(breaks = seq(0, 20, 0.5)) +
  scale_x_date(date_breaks = "6 months") +
  theme(legend.position = "none", axis.text.x = element_text(angle = 90))

# Replace the censored values with a character value including the < operator
ecoli <- ecoli |>
  ungroup() |> 
  mutate(censored_value = case_when(
    round(value_cfu_per_100ml, 2) == 0.67 ~ "<2",
    (round(value_cfu_per_100ml, 2) == 0.33 | value_cfu_per_100ml == 0.3) ~ "<1",
    round(value_cfu_per_100ml, 2) == 0.12 ~ "0",
    round(value_cfu_per_100ml, 2) == 0.22 ~ "0",
    round(value_cfu_per_100ml, 2) == 3.33 ~ "<10",
    round(value_cfu_per_100ml, 2) == 16.67 ~ "<50",
    round(value_cfu_per_100ml, 2) == 33.33 ~ "<100",
    round(value_cfu_per_100ml, 2) == 806.67 ~ ">2420",
    round(value_cfu_per_100ml, 2) == 3.48 ~ "4",
    round(value_cfu_per_100ml, 2) == 4.18 ~ "4",
    round(value_cfu_per_100ml, 4) == 2.7789 ~ "3",
    .default = as.character(value_cfu_per_100ml)
    )) |>
  mutate(censored_value = if_else(censored_value == "0", "ND", censored_value))

ecoli |>
  filter(date > "2024-01-01")

# Replace censored values with character value including < operator
faecal <- faecal |>
  ungroup() |> 
  mutate(censored_value = case_when(
    round(value_cfu_per_100ml, 2) == 0.67 ~ "<2",
    (round(value_cfu_per_100ml, 2) == 0.33 | value_cfu_per_100ml == 0.3) ~ "<1",
    round(value_cfu_per_100ml, 3) == 0.033 ~ "<1",
    round(value_cfu_per_100ml, 2) == 0.12 ~ "0",
    round(value_cfu_per_100ml, 2) == 0.22 ~ "0",
    round(value_cfu_per_100ml, 2) == 3.33 ~ "<10",
    round(value_cfu_per_100ml, 2) == 16.67 ~ "<50",
    round(value_cfu_per_100ml, 2) == 33.33 ~ "<100",
    round(value_cfu_per_100ml, 2) == 806.67 ~ ">2420",
    round(value_cfu_per_100ml, 2) == 3.48 ~ "4",
    round(value_cfu_per_100ml, 2) == 4.18 ~ "4",
    round(value_cfu_per_100ml, 2) == 2.48 ~ "2",
    value_cfu_per_100ml == 1.3 ~ "1",
    .default = as.character(value_cfu_per_100ml)
    )) |>
  mutate(censored_value = if_else(censored_value == "0", "ND", censored_value))

faecal |>
  filter(date > "2024-07-01")
```

Censored values can be found both at the lower detection limits and at the upper detection limits. Streaks at the upper limits can also indicate censored values

```{r upper-censored-values-ecoli}
ecoli |>
  ggplot(aes(x = date, y = value_cfu_per_100ml, colour = file)) +
  geom_point() +
  theme(
    legend.position = "none"
  ) +
  coord_cartesian(xlim = c(ymd("2014-01-01"), ymd("2025-01-01")))

# Upper limits above 60000 cfu per 100 ml
ecoli |>
  filter(value_cfu_per_100ml > 480, value_cfu_per_100ml < 750, date > "2020-07-01", date < "2022-01-01")

ecoli <- ecoli |>
  mutate(censored_value = case_when(
    value_cfu_per_100ml == 72588 ~ ">24196",
    value_cfu_per_100ml == 72570 ~ ">24190",
    value_cfu_per_100ml == 15000 ~ ">5000",
    value_cfu_per_100ml == 7260 ~ ">2420",
    value_cfu_per_100ml == 600 & date > "2020-04-01" & date < "2021-11-01" ~ ">200",
    .default = censored_value
  ))
```

```{r upper-censored-values-faecal}
faecal |>
  ggplot(aes(x = date, y = value_cfu_per_100ml, colour = file)) +
  geom_point() +
  theme(
    legend.position = "none"
  ) +
  coord_cartesian(xlim = c(ymd("2014-01-01"), ymd("2024-11-01")), ylim = c(0, 20000)) +
  scale_x_date(minor_breaks = "1 year")

# Upper limits above 60000 cfu per 100 ml
faecal |>
  filter(value_cfu_per_100ml == 4500)

faecal <- faecal |>
  mutate(censored_value = case_when(
    value_cfu_per_100ml == 72588 ~ ">24196",
    value_cfu_per_100ml == 24196 ~ ">24196",
    value_cfu_per_100ml == 15000 ~ ">5000",
    value_cfu_per_100ml == 7257 ~ ">2419",
    value_cfu_per_100ml == 450 & date > "2023-08-01" & date < "2024-11-01" ~ ">150",
    value_cfu_per_100ml == 4500 ~ ">1500",
    .default = censored_value
  ))
```

The obvious streaks that were divisible by 3 were divided by three and preceded by the > operator. Other streaks were visible in the 2023 period that are not a consistent value and cannot be easily divided by 3, and are not therefore obvious censored values. These values are of concern, as the frequency indicates a non-random distribution.
Values are quite commonly distributed along 50 unit intervals. From mid-2020 to end of 2021 the value of 600 was very common and was replace during this period with <200 because this is common censored value.

For faecal streptococci, similar censored values were replaced with their character equivalents.

```{r check-censored}
ecoli |>
  distinct(censored_value) |> 
  arrange(censored_value)

faecal |>
  distinct(censored_value) |>
  arrange(censored_value)
```

```{r plot-censored}
ecoli |>
  mutate(censored = str_detect(censored_value, "<|>")) |>
  ggplot(aes(x = date, y = value_cfu_per_100ml, colour = censored)) +
    geom_point() +
  coord_cartesian(xlim = c(ymd("2014-01-01"), ymd("2025-01-01")), ylim = c(0, 100))

faecal |>
  mutate(censored = str_detect(censored_value, "<|>")) |>
  ggplot(aes(x = date, y = value_cfu_per_100ml, colour = censored)) +
    geom_point() +
  coord_cartesian(xlim = c(ymd("2014-01-01"), ymd("2025-01-01")), ylim = c(0, 15))

```

```{r summary-statistics}
# Check summary statistics for ecoli
ecoli |>
  group_by(file) |>
  arrange(file) |>
  summarise(
    min_date = min(date),
    max_date = max(date),
    n = sum(!is.na(value_cfu_per_100ml)),
    min = min(value_cfu_per_100ml, na.rm = TRUE),
    max = max(value_cfu_per_100ml, na.rm = TRUE)
    )

# Check summary statistics for faecal streptococci
faecal |>
  group_by(file) |>
  arrange(file) |>
  summarise(
    min_date = min(date),
    max_date = max(date),
    n = sum(!is.na(value_cfu_per_100ml)),
    min = min(value_cfu_per_100ml, na.rm = TRUE),
    max = max(value_cfu_per_100ml, na.rm = TRUE)
    )
```

```{r check-sites}
# Create site name from the filename
sites_ecoli <- ecoli |>
  distinct(file, site_id) |>
  mutate(description = file |>
           str_remove("^\\d{1,3}_{1,2}") |>
           str_remove(".xlsm$") |>
           # str_remove("(SSB\\sand\\sCMB)|(CMB\\sand\\sSSB)") |>
           str_remove("\\([:upper:]{2,3}\\d{2}[:upper:]?\\)") |>
           str_replace_all("_", " ") |>
           str_to_upper() |>
           str_trim()) |>
  select(site_id, description) |>
  arrange(site_id)

sites_faecal <- faecal |>
  distinct(file, site_id) |>
  mutate(description = file |>
           str_remove("^\\d{1,3}_{1,2}") |>
           str_remove(".xlsm$") |>
           # str_remove("(SSB\\sand\\sCMB)|(CMB\\sand\\sSSB)") |>
           str_remove("\\([:upper:]{2,3}\\d{2}[:upper:]?\\)") |>
           str_replace_all("_", " ") |>
           str_to_upper() |>
           str_trim()) |>
  select(site_id, description) |>
  arrange(site_id)

# Check which sites are still unique
sites_ecoli |>
  distinct(site_id, description)

sites_faecal |>
  distinct(site_id, description)

# Get current sites
current <- tbl(con, I("coastal.sites")) |>
  collect()

current |>
  full_join(sites_ecoli) |>
  select(site_id, site_description, description) |>
  rename(description_current = site_description, description_ecoli = description)

current |>
  full_join(sites_faecal) |>
  select(site_id, site_description, description) |>
  rename(description_current = site_description, description_ecoli = description)
```

# Hazen Method

```{r test-hazen}
hazen_annual <- results |>
  group_by(year = year(date)) |>
  summarise(
    min_date = min(date),
    max_date = max(date),
    n_ecoli = sum(!is.na(ecoli_cfu_per_100ml)),
    hazen95_ecoli = quantile(ecoli_cfu_per_100ml, 0.95, type = 5, na.rm = TRUE),
    hazen90_ecoli = quantile(ecoli_cfu_per_100ml, 0.9, type = 5, na.rm = TRUE),
    hazen_category_ecoli = case_when(
      n_ecoli < 10 ~ "Not enough samples",
      hazen95_ecoli <= 100 ~ "Excellent",
      hazen95_ecoli <= 200 ~ "Good",
      hazen95_ecoli > 200 & hazen90_ecoli > 185 ~ "Poor",
      hazen95_ecoli > 200 & hazen90_ecoli < 185 ~ "Sufficient"
  ),
    n_faecal = sum(!is.na(faecal_streptococci_cfu_per_100ml)),
    hazen95_faecal = quantile(faecal_streptococci_cfu_per_100ml, 0.95, type = 5, na.rm = TRUE),
    hazen90_faecal = quantile(faecal_streptococci_cfu_per_100ml, 0.9, type = 5, na.rm = TRUE),
  hazen_category_faecal = case_when(
      n_faecal < 10 ~ "Not enough samples",
      hazen95_faecal <= 100 ~ "Excellent",
      hazen95_faecal <= 200 ~ "Good",
      hazen95_faecal > 200 & hazen90_faecal > 185 ~ "Poor",
      hazen95_faecal > 200 & hazen90_faecal < 185 ~ "Sufficient"
  )
  ) |>
  mutate(hazen_category_ecoli = fct(hazen_category_ecoli, levels = c("Not enough samples", "Poor", "Sufficient", "Good", "Excellent"))) |>
  mutate(hazen_category_faecal = fct(hazen_category_faecal, levels = c("Not enough samples", "Poor", "Sufficient", "Good", "Excellent")))
```

```{r test-hazen}
hazen_annual_site <- results |>
  group_by(year = year(date), site_id) |>
  summarise(
    min_date = min(date),
    max_date = max(date),
    n_ecoli = sum(!is.na(ecoli_cfu_per_100ml)),
    hazen95_ecoli = quantile(ecoli_cfu_per_100ml, 0.95, type = 5, na.rm = TRUE),
    hazen90_ecoli = quantile(ecoli_cfu_per_100ml, 0.9, type = 5, na.rm = TRUE),
    hazen_category_ecoli = case_when(
      n_ecoli < 10 ~ "Not enough samples",
      hazen95_ecoli <= 100 ~ "Excellent",
      hazen95_ecoli <= 200 ~ "Good",
      hazen95_ecoli > 200 & hazen90_ecoli > 185 ~ "Poor",
      hazen95_ecoli > 200 & hazen90_ecoli < 185 ~ "Sufficient"
  ),
    n_faecal = sum(!is.na(faecal_streptococci_cfu_per_100ml)),
    hazen95_faecal = quantile(faecal_streptococci_cfu_per_100ml, 0.95, type = 5, na.rm = TRUE),
    hazen90_faecal = quantile(faecal_streptococci_cfu_per_100ml, 0.9, type = 5, na.rm = TRUE),
  hazen_category_faecal = case_when(
      n_faecal < 10 ~ "Not enough samples",
      hazen95_faecal <= 100 ~ "Excellent",
      hazen95_faecal <= 200 ~ "Good",
      hazen95_faecal > 200 & hazen90_faecal > 185 ~ "Poor",
      hazen95_faecal > 200 & hazen90_faecal < 185 ~ "Sufficient"
  )
  ) |>
  mutate(hazen_category_ecoli = fct(hazen_category_ecoli, levels = c("Not enough samples", "Poor", "Sufficient", "Good", "Excellent"))) |>
  mutate(hazen_category_faecal = fct(hazen_category_faecal, levels = c("Not enough samples", "Poor", "Sufficient", "Good", "Excellent")))
```

```{r plot-hazen}
hazen_annual |>
  ggplot(aes(x = year)) +
  labs(x = "Year") +
  geom_tile(aes(fill = hazen_category_ecoli)) +
  scale_fill_brewer(name = "Water Quality Category", type = "div", palette = "RdYlGn")

RColorBrewer::display.brewer.all()
```

```{r}
sites |>
  inner_join(hazen_annual)
```

